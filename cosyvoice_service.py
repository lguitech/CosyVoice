### cosyvoice_service.py
# ----------------------
# è¿™æ˜¯æœåŠ¡çš„å…¥å£æ–‡ä»¶ï¼Œè¿›è¡Œ CosyVoice æ¨¡å‹åˆå§‹åŒ–ï¼Œå¯åŠ¨ FastAPI + WebSocket æœåŠ¡

import sys
import torch
import threading
from fastapi import FastAPI, WebSocket
import uvicorn

# åŠ è½½ CosyVoice2 ç›¸å…³æ¨¡å—
from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav

# è‡ªå®šä¹‰çš„æ¨¡å—
from inference_worker import inference_worker
from websocket_handler import handle_websocket
from request_queue import request_queue

# åŠ è½½ matcha æ¨¡å—çš„è·¯å¾„
sys.path.append('third_party/Matcha-TTS')

# åˆå§‹åŒ– CosyVoice2 æ¨¡å‹ï¼Œåªåˆå§‹åŒ–ä¸€æ¬¡
print("ğŸš€ CUDA å¯ç”¨:", torch.cuda.is_available())
cosyvoice = CosyVoice2(
    'pretrained_models/CosyVoice2-0.5B',
    load_jit=False,
    load_trt=True,
    load_vllm=False,
    fp16=True
)

# æ·»åŠ  zero-shot è¯´è¯äººï¼Œä¾¿äºåç»­é‡å¤ä½¿ç”¨
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
cosyvoice.add_zero_shot_spk('å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, 'my_zero_shot_spk')
cosyvoice.save_spkinfo()

# å¯åŠ¨æ¥å—è¯·æ±‚çš„èƒŒæ™¯çº¿ç¨‹
threading.Thread(target=inference_worker, args=(cosyvoice, request_queue), daemon=True).start()

# åˆ›å»º FastAPI app
app = FastAPI()

# WebSocket æ¥å£
@app.websocket("/tts")
async def websocket_endpoint(websocket: WebSocket):
    await handle_websocket(websocket)

# ç¨‹åºä¸»å…¥å£
if __name__ == '__main__':
    uvicorn.run("cosyvoice_service:app", host="0.0.0.0", port=8765)
