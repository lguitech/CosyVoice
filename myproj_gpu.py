import warnings
warnings.filterwarnings("ignore")
import sys
import torch
import torchaudio
from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav

# æ·»åŠ  matcha æ¨¡å—è·¯å¾„
sys.path.append('third_party/Matcha-TTS')

# æ£€æŸ¥ CUDA å¯ç”¨æ€§
print("ğŸš€ CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("ğŸ§  GPU:", torch.cuda.get_device_name(0))
else:
    print("âš ï¸ è­¦å‘Šï¼šå½“å‰æœªæ£€æµ‹åˆ°å¯ç”¨çš„ CUDA è®¾å¤‡ï¼Œå°†ä½¿ç”¨ CPUï¼")

# åˆå§‹åŒ– CosyVoice2ï¼ˆä½¿ç”¨ fp16 è¡¨ç¤ºå¯ç”¨ GPU æ¨ç†ï¼‰
cosyvoice = CosyVoice2(
    'pretrained_models/CosyVoice2-0.5B',
    load_jit=False,
    load_trt=True,
    load_vllm=False,
    fp16=True  # å¯ç”¨ GPUï¼ˆåŠç²¾åº¦ï¼‰ï¼Œè‹¥æ—  GPU ä¼šè‡ªåŠ¨ fallback åˆ° CPU
)

# æ‰“å°å½“å‰æ¨¡å‹æ‰€åœ¨è®¾å¤‡ï¼ˆå†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç† CUDAï¼‰
print("ğŸ“¦ å½“å‰è¿è¡Œè®¾å¤‡: CUDA" if torch.cuda.is_available() else "ğŸ“¦ å½“å‰è¿è¡Œè®¾å¤‡: CPU")


# åŠ è½½ 16kHz æç¤ºè¯­éŸ³ï¼ˆzero-shot promptï¼‰
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)

# æ·»åŠ  zero-shot è¯´è¯äºº
assert cosyvoice.add_zero_shot_spk(
    'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚',
    prompt_speech_16k,
    'my_zero_shot_spk'
)
print("ç°åœ¨å¼€å§‹æ¨ç†")
# æ¨ç†ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜ä¸º WAV æ–‡ä»¶
for i, j in enumerate(cosyvoice.inference_zero_shot(
    '''7æœˆ27æ—¥ï¼Œå°‘æ—å¯ºç®¡ç†å¤„å‘å¸ƒæƒ…å†µé€šæŠ¥ï¼šå°‘æ—å¯ºä½æŒé‡Šæ°¸ä¿¡æ¶‰å«Œåˆ‘äº‹çŠ¯ç½ªï¼ŒæŒªç”¨ä¾µå é¡¹ç›®èµ„é‡‘å¯ºé™¢èµ„äº§ï¼›''',
    '',
    '',
    zero_shot_spk_id='my_zero_shot_spk',
    stream=True)):

    output_path = f'zero_shot_{i}.wav'
    torchaudio.save(output_path, j['tts_speech'], cosyvoice.sample_rate)
    print(f"âœ… ä¿å­˜è¯­éŸ³åˆ°: {output_path}")

# ä¿å­˜è¯´è¯äººä¿¡æ¯ï¼ˆæ–¹ä¾¿åç»­é‡å¤ä½¿ç”¨ï¼‰
cosyvoice.save_spkinfo()

print("ğŸ“ å·²ä¿å­˜è¯´è¯äººä¿¡æ¯åˆ°æœ¬åœ°é…ç½®")

